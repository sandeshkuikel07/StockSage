{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1391e5bb-598d-49db-951d-0df76059e7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5ccb4768-c257-4154-81aa-9e0451d28428",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\ASUS\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt_tab.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt_tab')\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c619ba99-27cd-4d81-84c9-087d8fb5c295",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_gpu_memory():\n",
    "    \"\"\"Cleans up GPU memory.\"\"\"\n",
    "    gc.collect()\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "aa46e66d-517c-4745-a666-acfae5f95301",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_gpu_memory(required_memory_mb=2000):\n",
    "    \"\"\"Checks if there's enough GPU memory.\"\"\"\n",
    "    if not torch.cuda.is_available():\n",
    "        return False\n",
    "    total_memory = torch.cuda.get_device_properties(0).total_memory / 1024**2\n",
    "    allocated_memory = torch.cuda.memory_allocated() / 1024**2\n",
    "    available_memory = total_memory - allocated_memory\n",
    "    print(f\"\\nGPU Memory Available: {available_memory:.2f} MB\")\n",
    "    return available_memory >= required_memory_mb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "43feaeaa-4aa9-470a-b3fa-8079a32c7305",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_memory_usage(df):\n",
    "    \"\"\"Reduces memory usage of a dataframe.\"\"\"\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "\n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    print(f'Memory usage reduced from {start_mem:.2f} MB to {end_mem:.2f} MB ({100 * (start_mem - end_mem) / start_mem:.2f}% reduction)')\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8e3f4324-52a5-4af8-ac97-d7819a2fddee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_nltk():\n",
    "    \"\"\"Set up NLTK resources and verify their availability.\"\"\"\n",
    "    # Check all possible NLTK data directories\n",
    "    possible_paths = [\n",
    "        os.path.expanduser('~/nltk_data'),\n",
    "        os.path.expanduser('~/AppData/Roaming/nltk_data'),\n",
    "        os.path.expanduser('~/AppData/Local/Programs/Python/Python312/nltk_data'),\n",
    "    ]\n",
    "    \n",
    "    # Add all possible paths to NLTK's search path\n",
    "    for path in possible_paths:\n",
    "        if path not in nltk.data.path:\n",
    "            nltk.data.path.append(path)\n",
    "    \n",
    "    # Download required NLTK data\n",
    "    nltk.download('punkt')\n",
    "    nltk.download('stopwords')\n",
    "    \n",
    "    # Verify resources are available\n",
    "    try:\n",
    "        # Test tokenizer\n",
    "        test_text = \"This is a test sentence.\"\n",
    "        tokens = word_tokenize(test_text)\n",
    "        # Test stopwords\n",
    "        stop_words = set(stopwords.words('english'))\n",
    "        print(\"NLTK setup successful!\")\n",
    "        return True\n",
    "    except LookupError as e:\n",
    "        print(f\"Error verifying NLTK resources: {str(e)}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e67c202c-5da4-430f-9412-c1632dc744e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    \"\"\"Clean the input text by removing punctuation and stopwords.\"\"\"\n",
    "    # Convert to string and lowercase\n",
    "    text = str(text).lower()\n",
    "    \n",
    "    # Remove punctuation\n",
    "    text = ''.join(char for char in text if char.isalnum() or char.isspace())\n",
    "    \n",
    "    # Tokenize and remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = word_tokenize(text)\n",
    "    cleaned_tokens = [word for word in tokens if word not in stop_words]\n",
    "    \n",
    "    # Join tokens back into a string\n",
    "    cleaned_text = ' '.join(cleaned_tokens)\n",
    "    \n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "61b89fc6-9293-4936-a1f4-321708174740",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_finbert_sentiment_scores(text, sentiment_pipeline):\n",
    "    \"\"\"Get FinBERT sentiment scores for the given text.\"\"\"\n",
    "    try:\n",
    "        # Get raw pipeline output\n",
    "        results = sentiment_pipeline(text, truncation=True, max_length=512)\n",
    "        \n",
    "        if isinstance(results, list) and len(results) > 0:\n",
    "            # Extract scores from the first result (list of dictionaries)\n",
    "            results = results[0]\n",
    "        else:\n",
    "            return {'positive': 0, 'negative': 0, 'neutral': 0}\n",
    "        \n",
    "        # Extract sentiment scores\n",
    "        scores = {item['label']: item['score'] for item in results}\n",
    "        \n",
    "        return {\n",
    "            'positive': scores.get('positive', 0),\n",
    "            'negative': scores.get('negative', 0),\n",
    "            'neutral': scores.get('neutral', 0)\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"Error analyzing text with FinBERT: {str(e)}\")\n",
    "        return {'positive': 0, 'negative': 0, 'neutral': 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1fe9935e-3dbe-46ca-80f5-15fdd858c7fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_finbert_composite(positive_score, negative_score, neutral_score):\n",
    "    \"\"\"\n",
    "    Compute a single sentiment score from FinBERT's positive, negative, and neutral scores.\n",
    "    Returns a value in the range [-1, 1].\n",
    "    \"\"\"\n",
    "    total = positive_score + negative_score + neutral_score\n",
    "    if total == 0:\n",
    "        return 0  # If all scores are zero, default to neutral\n",
    "    \n",
    "    # Weighted sum interpretation:\n",
    "    #   positive contributes +1\n",
    "    #   negative contributes -1\n",
    "    #   neutral contributes 0\n",
    "    weighted_sum = (positive_score * 1) + (negative_score * -1) + (neutral_score * 0)\n",
    "\n",
    "    return weighted_sum / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2a1cb488-6463-420e-946f-2a83f8a55579",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_finbert_sentiment(input_path, output_path=None):\n",
    "    \"\"\"\n",
    "    Process news data, clean text, and apply FinBERT sentiment analysis.\n",
    "    Save the results to a CSV file with only the finbert_composite score.\n",
    "    \n",
    "    Args:\n",
    "        input_path: Path to the input CSV file containing news data\n",
    "        output_path: Path to save the output CSV file (default: 'finbert_sentiment_df.csv')\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with FinBERT sentiment analysis results\n",
    "    \"\"\"\n",
    "    if output_path is None:\n",
    "        output_path = 'finbert_sentiment_df.csv'\n",
    "    \n",
    "    print(\"Setting up NLTK...\")\n",
    "    setup_nltk()\n",
    "    \n",
    "    print(f\"Reading news data from {input_path}...\")\n",
    "    try:\n",
    "        df = pd.read_csv(input_path, parse_dates=['Date'], index_col='Date')\n",
    "    except (FileNotFoundError, KeyError):\n",
    "        try:\n",
    "            # Try without the Date column as index\n",
    "            df = pd.read_csv(input_path)\n",
    "            # Check if 'Date' column exists\n",
    "            if 'Date' in df.columns:\n",
    "                df['Date'] = pd.to_datetime(df['Date'])\n",
    "                df.set_index('Date', inplace=True)\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Error: Input CSV file not found at {input_path}\")\n",
    "            return None\n",
    "    \n",
    "    # Check if we have the necessary columns\n",
    "    if 'Title' in df.columns:\n",
    "        news_column = 'Title'\n",
    "    elif 'News' in df.columns:\n",
    "        news_column = 'News'\n",
    "    else:\n",
    "        print(\"Error: Could not find a column named 'Title' or 'News' in the CSV file.\")\n",
    "        return None\n",
    "    \n",
    "    print(\"Cleaning news text...\")\n",
    "    df['Cleaned News'] = df[news_column].apply(clean_text)\n",
    "    \n",
    "    print(\"Initializing FinBERT model...\")\n",
    "    # Initialize FinBERT model and tokenizer\n",
    "    model_name = \"ProsusAI/finbert\"\n",
    "    \n",
    "    try:\n",
    "        # Check if we have enough GPU memory\n",
    "        has_gpu = check_gpu_memory(2000)\n",
    "        device = torch.device(\"cuda\" if has_gpu else \"cpu\")\n",
    "        print(f\"Using device: {device}\")\n",
    "        \n",
    "        # Load model to appropriate device\n",
    "        tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        model = AutoModelForSequenceClassification.from_pretrained(model_name).to(device)\n",
    "        sentiment_pipeline = pipeline(\"text-classification\", model=model, tokenizer=tokenizer, \n",
    "                                      return_all_scores=True, device=0 if has_gpu else -1)\n",
    "        \n",
    "        print(\"Applying FinBERT sentiment analysis (this may take a while)...\")\n",
    "        # Apply FinBERT sentiment in batches to manage memory\n",
    "        batch_size = 32\n",
    "        scores = []\n",
    "        \n",
    "        for i in range(0, len(df), batch_size):\n",
    "            batch_texts = df['Cleaned News'].iloc[i:i+batch_size].tolist()\n",
    "            batch_scores = []\n",
    "            \n",
    "            for text in batch_texts:\n",
    "                result = get_finbert_sentiment_scores(text, sentiment_pipeline)\n",
    "                batch_scores.append(result)\n",
    "            \n",
    "            scores.extend(batch_scores)\n",
    "            \n",
    "            # Clear GPU memory after each batch\n",
    "            clean_gpu_memory()\n",
    "            \n",
    "        # Add sentiment scores to the dataframe\n",
    "        df['positive_score'] = [score['positive'] for score in scores]\n",
    "        df['negative_score'] = [score['negative'] for score in scores]\n",
    "        df['neutral_score'] = [score['neutral'] for score in scores]\n",
    "        \n",
    "        # Create composite FinBERT score\n",
    "        df['finbert_composite'] = df.apply(\n",
    "            lambda row: compute_finbert_composite(\n",
    "                row['positive_score'], row['negative_score'], row['neutral_score']),\n",
    "            axis=1)\n",
    "        \n",
    "        # Free up GPU memory after processing\n",
    "        clean_gpu_memory()\n",
    "        \n",
    "        # Create a simplified dataframe with only the necessary columns\n",
    "        result_df = df[['finbert_composite', 'Cleaned News']].copy()\n",
    "        \n",
    "        # Optionally reduce memory usage before saving\n",
    "        result_df = reduce_memory_usage(result_df)\n",
    "        \n",
    "        # Save the results to CSV\n",
    "        print(f\"Saving FinBERT sentiment results to {output_path}...\")\n",
    "        result_df.to_csv(output_path)\n",
    "        print(f\"FinBERT sentiment analysis complete! Results saved to {output_path}\")\n",
    "        \n",
    "        return result_df\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error during sentiment analysis: {str(e)}\")\n",
    "        # Clean up memory in case of error\n",
    "        clean_gpu_memory()\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "89b48464-2462-4094-8cf6-b09bacb0c730",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting FinBERT sentiment analysis for C:\\Users\\ASUS\\Desktop\\stocksage\\sharesansar_news_NABIL.csv...\n",
      "Setting up NLTK...\n",
      "NLTK setup successful!\n",
      "Reading news data from C:\\Users\\ASUS\\Desktop\\stocksage\\sharesansar_news_NABIL.csv...\n",
      "Cleaning news text...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\ASUS\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ASUS\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing FinBERT model...\n",
      "\n",
      "GPU Memory Available: 6135.38 MB\n",
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\pipelines\\text_classification.py:106: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying FinBERT sentiment analysis (this may take a while)...\n",
      "Memory usage reduced from 0.02 MB to 0.01 MB (25.00% reduction)\n",
      "Saving FinBERT sentiment results to C:\\Users\\ASUS\\Desktop\\stocksage\\combined_sentiment_df_NABIL.csv...\n",
      "FinBERT sentiment analysis complete! Results saved to C:\\Users\\ASUS\\Desktop\\stocksage\\combined_sentiment_df_NABIL.csv\n",
      "\n",
      "Sample of FinBERT sentiment analysis results:\n",
      "            finbert_composite\n",
      "Date                         \n",
      "2025-01-23           0.063171\n",
      "2025-01-20           0.683594\n",
      "2025-01-19           0.030060\n",
      "2025-01-16           0.037415\n",
      "2025-01-13           0.863281\n",
      "\n",
      "Process completed!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\formats\\format.py:1458: RuntimeWarning: overflow encountered in cast\n",
      "  has_large_values = (abs_vals > 1e6).any()\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Example usage\n",
    "    input_file = r\"C:\\Users\\ASUS\\Desktop\\stocksage\\sharesansar_news_NABIL.csv\"  # Change this to your input file path\n",
    "    output_file = r\"C:\\Users\\ASUS\\Desktop\\stocksage\\combined_sentiment_df_NABIL.csv\"  # Change this to your desired output file path\n",
    "    \n",
    "    print(f\"\\nStarting FinBERT sentiment analysis for {input_file}...\")\n",
    "    sentiment_df = process_finbert_sentiment(input_file, output_file)\n",
    "    \n",
    "    if sentiment_df is not None:\n",
    "        print(\"\\nSample of FinBERT sentiment analysis results:\")\n",
    "        print(sentiment_df[['finbert_composite']].head())\n",
    "    \n",
    "    print(\"\\nProcess completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22116e42-565c-42ff-9fb4-1c99b968afd3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118864f3-fd56-4186-80cb-08af8346501c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f63376-2b24-4a5b-8b5e-21945452243b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8370db8-0924-4fc1-aaf3-6726d94c9290",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771582ce-96d1-4b26-a860-bce5a154336e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1727cb05-10ad-435f-a4cb-bba9554f219f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
